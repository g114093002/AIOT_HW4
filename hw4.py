"""
è³‡æ–™å¢å¼·å°å…«å“¥è¾¨è­˜æ¨¡å‹çš„å½±éŸ¿åˆ†æ
Data Augmentation Impact on Mynah Bird Classification using Transfer Learning

æœ¬æ¨¡å¡Šæä¾›äº†å®Œæ•´çš„æ•¸æ“šå¢å¼·å’Œé·ç§»å­¸ç¿’å¯¦ç¾æ¡†æ¶ã€‚
å¯ä»¥ç¨ç«‹é‹è¡Œæ­¤æ–‡ä»¶æˆ–å°å…¥åˆ° Jupyter Notebook ä¸­ä½¿ç”¨ã€‚
"""

import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.transforms import RandomErasing

from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                            f1_score, confusion_matrix, classification_report)

# ============================================================================
# é…ç½®å¸¸æ•¸
# ============================================================================

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 50
LEARNING_RATE = 0.001
WEIGHT_DECAY = 1e-4
PATIENCE = 10

# éš¨æ©Ÿç¨®å­
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(RANDOM_SEED)

# ============================================================================
# è‡ªå®šç¾©æ•¸æ“šé›†é¡
# ============================================================================

class MynahDataset(Dataset):
    """å…«å“¥é³¥åœ–åƒæ•¸æ“šé›†é¡"""
    
    def __init__(self, image_paths, labels, transforms=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transforms = transforms
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        img = Image.open(img_path).convert('RGB')
        
        if self.transforms:
            img = self.transforms(img)
        
        return img, label


# ============================================================================
# æ•¸æ“šåŠ è¼‰å’Œå¢å¼·å®šç¾©
# ============================================================================

def create_augmentation_strategies():
    """å‰µå»º5ç¨®ä¸åŒçš„æ•¸æ“šå¢å¼·ç­–ç•¥"""
    
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                   std=[0.229, 0.224, 0.225])
    
    strategies = {
        'Baseline': transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            normalize
        ]),
        
        'Geometric': transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=20),
            transforms.ToTensor(),
            normalize
        ]),
        
        'Color': transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, 
                                 saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            normalize
        ]),
        
        'Combined': transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=20),
            transforms.ColorJitter(brightness=0.2, contrast=0.2,
                                 saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            normalize
        ]),
        
        'Occlusion': transforms.Compose([
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(degrees=20),
            transforms.ColorJitter(brightness=0.2, contrast=0.2,
                                 saturation=0.2, hue=0.1),
            transforms.ToTensor(),
            normalize,
            RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0)
        ]),
    }
    
    test_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        normalize
    ])
    
    return strategies, test_transform


def load_dataset(data_dir, test_size=0.2, val_size=0.1):
    """åŠ è¼‰æ•¸æ“šé›†"""
    
    image_paths = []
    labels = []
    class_names = []
    
    data_dir = Path(data_dir)
    
    if data_dir.exists():
        for class_dir in sorted(data_dir.iterdir()):
            if class_dir.is_dir():
                class_name = class_dir.name
                class_names.append(class_name)
                class_idx = len(class_names) - 1
                
                for ext in ['*.jpg', '*.jpeg', '*.png']:
                    for img_file in class_dir.glob(ext):
                        image_paths.append(str(img_file))
                        labels.append(class_idx)
    
    image_paths = np.array(image_paths)
    labels = np.array(labels)
    
    n_samples = len(image_paths)
    indices = np.arange(n_samples)
    np.random.shuffle(indices)
    
    test_count = int(n_samples * test_size)
    val_count = int(n_samples * val_size)
    train_count = n_samples - test_count - val_count
    
    train_idx = indices[:train_count]
    val_idx = indices[train_count:train_count + val_count]
    test_idx = indices[train_count + val_count:]
    
    return image_paths, labels, class_names, train_idx, val_idx, test_idx


def create_dataloaders(image_paths, labels, train_idx, val_idx, test_idx,
                       augmentation_strategy, batch_size=BATCH_SIZE):
    """å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨"""
    
    _, test_transform = create_augmentation_strategies()
    
    train_dataset = MynahDataset(
        image_paths[train_idx],
        labels[train_idx],
        transforms=augmentation_strategy
    )
    
    val_dataset = MynahDataset(
        image_paths[val_idx],
        labels[val_idx],
        transforms=test_transform
    )
    
    test_dataset = MynahDataset(
        image_paths[test_idx],
        labels[test_idx],
        transforms=test_transform
    )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                            num_workers=0, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                           num_workers=0, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,
                            num_workers=0, pin_memory=True)
    
    return train_loader, val_loader, test_loader


# ============================================================================
# æ¨¡å‹ç›¸é—œå‡½æ•¸
# ============================================================================

def build_model(num_classes):
    """æ§‹å»ºResNet18é·ç§»å­¸ç¿’æ¨¡å‹"""
    
    model = models.resnet18(pretrained=True)
    
    # å‡çµæ—©æœŸå±¤
    for param in model.layer1.parameters():
        param.requires_grad = False
    for param in model.layer2.parameters():
        param.requires_grad = False
    
    # ä¿®æ”¹æœ€å¾Œçš„å…¨é€£æ¥å±¤
    in_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(in_features, 256),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(256, num_classes)
    )
    
    return model


def count_parameters(model):
    """è¨ˆç®—æ¨¡å‹åƒæ•¸"""
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total, trainable


# ============================================================================
# è¨“ç·´ç›¸é—œå‡½æ•¸
# ============================================================================

def train_epoch(model, train_loader, criterion, optimizer, device):
    """è¨“ç·´ä¸€å€‹ epoch"""
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0
    
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)
    
    avg_loss = total_loss / len(train_loader)
    accuracy = correct / total
    return avg_loss, accuracy


def validate(model, val_loader, criterion, device):
    """é©—è­‰æ¨¡å‹"""
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
    
    avg_loss = total_loss / len(val_loader)
    accuracy = correct / total
    return avg_loss, accuracy


def evaluate_model(model, test_loader, device):
    """è©•ä¼°æ¨¡å‹"""
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.numpy())
    
    return np.array(all_preds), np.array(all_labels)


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def main(data_dir='mynah_data', results_dir='results', models_dir='models'):
    """ä¸»ç¨‹åº"""
    
    # å‰µå»ºç›®éŒ„
    Path(results_dir).mkdir(exist_ok=True)
    Path(models_dir).mkdir(exist_ok=True)
    
    print("="*80)
    print("è³‡æ–™å¢å¼·å°å…«å“¥è¾¨è­˜æ¨¡å‹çš„å½±éŸ¿åˆ†æ")
    print("="*80)
    
    # åŠ è¼‰æ•¸æ“š
    print("\nğŸ“‚ æ­£åœ¨åŠ è¼‰æ•¸æ“š...")
    try:
        image_paths, labels, class_names, train_idx, val_idx, test_idx = \
            load_dataset(data_dir)
    except Exception as e:
        print(f"âŒ åŠ è¼‰æ•¸æ“šå¤±æ•—: {e}")
        return
    
    num_classes = len(class_names)
    print(f"âœ“ å·²åŠ è¼‰ {len(image_paths)} å€‹åœ–åƒï¼Œ{num_classes} å€‹é¡åˆ¥")
    
    # å‰µå»ºå¢å¼·ç­–ç•¥
    strategies, test_transform = create_augmentation_strategies()
    print(f"âœ“ å·²å®šç¾© {len(strategies)} ç¨®å¢å¼·ç­–ç•¥")
    
    # è¨“ç·´æ‰€æœ‰æ¨¡å‹
    all_histories = {}
    trained_models = {}
    
    for strategy_name in strategies.keys():
        print(f"\n{'='*60}")
        print(f"è¨“ç·´ {strategy_name} æ¨¡å‹")
        print(f"{'='*60}")
        
        # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
        train_loader, val_loader, test_loader = create_dataloaders(
            image_paths, labels, train_idx, val_idx, test_idx,
            strategies[strategy_name]
        )
        
        # æ§‹å»ºæ¨¡å‹
        model = build_model(num_classes).to(DEVICE)
        
        # å®šç¾©å„ªåŒ–å™¨å’Œæå¤±å‡½æ•¸
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE,
                             weight_decay=WEIGHT_DECAY)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
        
        # è¨“ç·´
        best_val_acc = 0.0
        patience_counter = 0
        history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': []
        }
        
        for epoch in range(EPOCHS):
            train_loss, train_acc = train_epoch(model, train_loader,
                                               criterion, optimizer, DEVICE)
            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)
            
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['val_loss'].append(val_loss)
            history['val_acc'].append(val_acc)
            
            scheduler.step()
            
            if (epoch + 1) % 10 == 0:
                print(f"Epoch [{epoch+1}/{EPOCHS}] | "
                      f"Val Acc: {val_acc:.4f}")
            
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                torch.save(model.state_dict(),
                          Path(models_dir) / f'{strategy_name}_best.pth')
            else:
                patience_counter += 1
                if patience_counter >= PATIENCE:
                    print(f"æ—©åœ: é©—è­‰æº–ç¢ºç‡ {PATIENCE} å€‹ epoch æœªæ”¹é€²")
                    break
        
        # åŠ è¼‰æœ€ä½³æ¨¡å‹
        model.load_state_dict(torch.load(Path(models_dir) / f'{strategy_name}_best.pth'))
        all_histories[strategy_name] = history
        trained_models[strategy_name] = model
        
        # è©•ä¼°
        y_pred, y_true = evaluate_model(model, test_loader, DEVICE)
        test_acc = accuracy_score(y_true, y_pred)
        print(f"âœ“ æ¸¬è©¦æº–ç¢ºç‡: {test_acc:.4f}")
    
    print(f"\nâœ… æ‰€æœ‰ {len(strategies)} å€‹æ¨¡å‹è¨“ç·´å®Œæˆ")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {models_dir}")
    print(f"ğŸ“Š çµæœå·²ä¿å­˜è‡³: {results_dir}")


if __name__ == '__main__':
    # æª¢æŸ¥æ•¸æ“šç›®éŒ„
    data_dir = 'mynah_data'
    if not Path(data_dir).exists():
        print(f"âŒ éŒ¯èª¤: æ•¸æ“šç›®éŒ„ '{data_dir}' ä¸å­˜åœ¨")
        print(f"è«‹å°‡æ•¸æ“šæ”¾åœ¨ {Path.cwd() / data_dir} ç›®éŒ„ä¸‹")
        print("æ•¸æ“šæ ¼å¼: mynah_data/é¡åˆ¥å1/image1.jpg, mynah_data/é¡åˆ¥å2/image2.jpg")
        sys.exit(1)
    
    # é‹è¡Œä¸»ç¨‹åº
    main(data_dir='mynah_data', results_dir='results', models_dir='models')
